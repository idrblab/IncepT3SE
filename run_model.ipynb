{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### env = 'tf24-GPU (Python 3.7.13)'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pkg.model import T3SEClassEstimator\n",
    "from pkg.loss import focal_loss\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load train data\n",
    "\n",
    "X_pos_onehot = np.load(\"..//dataset_process//train-pos-processed.npy\")\n",
    "X_neg_onehot = np.load(\"..//dataset_process//train-neg-processed.npy\")\n",
    "\n",
    "X_pos_onehot = tf.expand_dims(X_pos_onehot, -1)\n",
    "X_neg_onehot = tf.expand_dims(X_neg_onehot, -1)\n",
    "print('pos_data-onehot shape:', X_pos_onehot.shape)\n",
    "print('neg_data-onehot shape:', X_neg_onehot.shape)\n",
    "\n",
    "### load test data\n",
    "\n",
    "T3SE_d_onehot = np.load(\"..//dataset_process//test-processed.npy\")\n",
    "testX_d_onehot = tf.expand_dims(T3SE_d_onehot, -1)\n",
    "print('testX_d_onehot shape: ', testX_d_onehot.shape)\n",
    "\n",
    "testY_d = np.concatenate((np.ones(100), np.zeros(100)), axis=0)\n",
    "testY_d = pd.get_dummies(testY_d).values  # one-hot\n",
    "print('testY_d shape:        ', testY_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 fold cross-validation\n",
    "\n",
    "# X_neg_onehot = X_neg_onehot  # all species\n",
    "X_neg_onehot_np = X_neg_onehot.numpy()\n",
    "index = [i for i in range(len(X_neg_onehot_np))]\n",
    "np.random.seed(31)\n",
    "np.random.shuffle(index)\n",
    "X_neg_onehot_np_random = X_neg_onehot_np[index]\n",
    "# X_neg_onehot_np_random = X_neg_onehot_np[index]\n",
    "X_neg_onehot = tf.convert_to_tensor(X_neg_onehot_np_random, dtype=tf.int32)\n",
    "\n",
    "X_pos_onehot_np = X_pos_onehot.numpy()\n",
    "index = [i for i in range(len(X_pos_onehot_np))]\n",
    "np.random.seed(31)\n",
    "np.random.shuffle(index)\n",
    "X_pos_onehot_np_random = X_pos_onehot_np[index]\n",
    "# X_pos_onehot_np_random = X_pos_onehot_np[index]\n",
    "X_pos_onehot = tf.convert_to_tensor(X_pos_onehot_np_random, dtype=tf.int32)\n",
    "\n",
    "X_onehot = np.append(X_pos_onehot, X_neg_onehot, axis=0)\n",
    "Y = np.append(np.ones(len(X_pos_onehot)), np.zeros(len(X_neg_onehot)))\n",
    "Y = pd.get_dummies(Y).values  # label one-hot encoding\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=31)\n",
    "fold = 0\n",
    "for train_index , test_index in kf.split(X_onehot):\n",
    "    # split train data\n",
    "    fold += 1    \n",
    "    trainX_onehot, trainY = X_onehot[train_index], Y[train_index]\n",
    "    testX_onehot, testY = X_onehot[test_index], Y[test_index]\n",
    "    print('fold:', fold)\n",
    "    print('trainX_onehot shape:', trainX_onehot.shape, 'trainY shape:', trainY.shape)\n",
    "    print('testX_onehot shape: ', testX_onehot.shape , 'testY shape:', testY.shape)\n",
    "    # train model\n",
    "    alpha = len(X_pos_onehot)/(len(X_pos_onehot)+len(X_neg_onehot)*1)\n",
    "    # loss_fun = focal_loss(gamma=[2, 2], alpha=alpha)\n",
    "    loss_fun = focal_loss(gamma=[1, 1], alpha=0.5)\n",
    "    clf = T3SEClassEstimator(n_outputs=2, fmap_shape1=(200, 20, 1), dense_layers=[256, 32], epochs=8000, monitor='val_auc', metric='PRC',  # monitor = 'val_loss', 'val_auc'\n",
    "                            gpuid=0, batch_size=128, lr=1e-4, decay=1e-3, loss=loss_fun)  # metric='ACC', 'PRC', 'ROC'\n",
    "    clf.patience = 22\n",
    "    clf.fit(trainX_onehot[:,:200,:,:], trainY, (testX_onehot[:,:200,:,:], testX_onehot[:,:200,:,:]), (testY, testY))\n",
    "    print('Best epochs: %.2f, Best loss: %.2f' % (clf._performance.best_epoch, clf._performance.best))\n",
    "    # save model\n",
    "    import time\n",
    "    curr_time = (time.strftime(\"%m-%d-%H%M\",time.localtime()))\n",
    "    # clf._model.save('./saved_model/'+curr_time+'-5fold.h5')\n",
    "    clf._model.save('./saved_model/'+curr_time+'-5fold-NoFocalLoss.h5')\n",
    "    # record result\n",
    "    proba1 = clf._model.predict(testX_onehot[:,:200,:,:])\n",
    "    pre_dual = np.round(proba1)\n",
    "    with open('./saved_model/5fold-result.txt', 'a+')as f:\n",
    "        f.write('\\n'+curr_time+'\\n')\n",
    "        TP , TN, FP, FN = 0, 0, 0, 0\n",
    "        for i in range(len(testY)):\n",
    "            if str(int(pre_dual[i][1])) == '1' and str(int(testY[i][1])) == '1':\n",
    "                TP += 1\n",
    "            if str(int(pre_dual[i][1])) == '0' and str(int(testY[i][1])) == '1':\n",
    "                FN += 1\n",
    "            if str(int(pre_dual[i][1])) == '0' and str(int(testY[i][1])) == '0':\n",
    "                TN += 1\n",
    "            if str(int(pre_dual[i][1])) == '1' and str(int(testY[i][1])) == '0':\n",
    "                FP += 1\n",
    "        f.write('TP\\tFN\\tTN\\tFP\\n')\n",
    "        f.write(str(TP)+'\\t'+str(FN)+'\\t'+str(TN)+'\\t'+str(FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 fold cross-validation (E.coli. only)\n",
    "\n",
    "# X_neg_onehot = X_neg_onehot[3384:4258]  # E.coli only\n",
    "X_neg_onehot_np = X_neg_onehot[3384:4258].numpy()\n",
    "index = [i for i in range(len(X_neg_onehot_np))]\n",
    "np.random.seed(31)\n",
    "np.random.shuffle(index)\n",
    "X_neg_onehot_np_random = X_neg_onehot_np[index]\n",
    "X_neg_onehot = tf.convert_to_tensor(X_neg_onehot_np_random, dtype=tf.int32)\n",
    "\n",
    "X_pos_onehot_np = X_pos_onehot.numpy()\n",
    "index = [i for i in range(len(X_pos_onehot_np))]\n",
    "np.random.seed(31)\n",
    "np.random.shuffle(index)\n",
    "X_pos_onehot_np_random = X_pos_onehot_np[index]\n",
    "X_pos_onehot = tf.convert_to_tensor(X_pos_onehot_np_random, dtype=tf.int32)\n",
    "\n",
    "X_onehot = np.append(X_pos_onehot, X_neg_onehot, axis=0)\n",
    "Y = np.append(np.ones(len(X_pos_onehot)), np.zeros(len(X_neg_onehot)))\n",
    "Y = pd.get_dummies(Y).values  # label one-hot encoding\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=31)\n",
    "fold = 0\n",
    "for train_index , test_index in kf.split(X_onehot):\n",
    "    # split train data\n",
    "    fold += 1    \n",
    "    trainX_onehot, trainY = X_onehot[train_index], Y[train_index]\n",
    "    testX_onehot, testY = X_onehot[test_index], Y[test_index]\n",
    "    print('fold:', fold)\n",
    "    print('trainX_onehot shape:', trainX_onehot.shape, 'trainY shape:', trainY.shape)\n",
    "    print('testX_onehot shape: ', testX_onehot.shape , 'testY shape:', testY.shape)\n",
    "    # train model\n",
    "    alpha = len(X_pos_onehot)/(len(X_pos_onehot)+len(X_neg_onehot)*1)\n",
    "    loss_fun = focal_loss(gamma=[2, 2], alpha=alpha)\n",
    "    clf = T3SEClassEstimator(n_outputs=2, fmap_shape1=(200, 20, 1), dense_layers=[256, 32], epochs=8000, monitor='val_auc', metric='PRC',  # monitor = 'val_loss', 'val_auc'\n",
    "                            gpuid=0, batch_size=128, lr=1e-4, decay=1e-3, loss=loss_fun)  # metric='ACC', 'PRC', 'ROC'\n",
    "    clf.patience = 22\n",
    "    clf.fit(trainX_onehot[:,:200,:,:], trainY, (testX_onehot[:,:200,:,:], testX_onehot[:,:200,:,:]), (testY, testY))\n",
    "    print('Best epochs: %.2f, Best loss: %.2f' % (clf._performance.best_epoch, clf._performance.best))\n",
    "    # save model\n",
    "    import time\n",
    "    curr_time = (time.strftime(\"%m-%d-%H%M\",time.localtime()))\n",
    "    clf._model.save('./saved_model/'+curr_time+'-5fold.h5')\n",
    "    # record result\n",
    "    proba1 = clf._model.predict(testX_onehot[:,:200,:,:])\n",
    "    pre_dual = np.round(proba1)\n",
    "    with open('./saved_model/5fold-result.txt', 'a+')as f:\n",
    "        f.write('\\n'+curr_time+'\\n')\n",
    "        TP , TN, FP, FN = 0, 0, 0, 0\n",
    "        for i in range(len(testY)):\n",
    "            if str(int(pre_dual[i][1])) == '1' and str(int(testY[i][1])) == '1':\n",
    "                TP += 1\n",
    "            if str(int(pre_dual[i][1])) == '0' and str(int(testY[i][1])) == '1':\n",
    "                FN += 1\n",
    "            if str(int(pre_dual[i][1])) == '0' and str(int(testY[i][1])) == '0':\n",
    "                TN += 1\n",
    "            if str(int(pre_dual[i][1])) == '1' and str(int(testY[i][1])) == '0':\n",
    "                FP += 1\n",
    "        f.write('TP\\tFN\\tTN\\tFP\\n')\n",
    "        f.write(str(TP)+'\\t'+str(FN)+'\\t'+str(TN)+'\\t'+str(FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split train data\n",
    "\n",
    "X_onehot = np.append(X_pos_onehot, X_neg_onehot, axis=0)\n",
    "Y = np.append(np.ones(len(X_pos_onehot)), np.zeros(len(X_neg_onehot)))\n",
    "Y = pd.get_dummies(Y).values  # one-hot\n",
    "\n",
    "# split dataset\n",
    "def Rdsplit(df, random_state=31, split_size=[1, 0, 0]):\n",
    "    base_indices = np.arange(len(df))\n",
    "    base_indices = shuffle(base_indices, random_state=random_state)\n",
    "    nb_test = int(len(base_indices) * split_size[2])\n",
    "    nb_val = int(len(base_indices) * split_size[1])\n",
    "    test_idx = base_indices[0:nb_test]\n",
    "    valid_idx = base_indices[nb_test:(nb_test + nb_val)]\n",
    "    train_idx = base_indices[(nb_test + nb_val):len(base_indices)]\n",
    "    return train_idx, valid_idx, test_idx\n",
    "\n",
    "train_idx, valid_idx, test_idx = Rdsplit(Y)\n",
    "trainX_onehot = X_onehot[train_idx]\n",
    "trainY = Y[train_idx][:]\n",
    "validX_onehot = X_onehot[valid_idx]\n",
    "validY = Y[valid_idx][:]\n",
    "testX_onehot = X_onehot[test_idx]\n",
    "testY = Y[test_idx]\n",
    "print('trainX_onehot shape:', trainX_onehot.shape, 'trainY shape:', trainY.shape)\n",
    "print('validX_onehot shape:', validX_onehot.shape, 'validY shape:', validY.shape)\n",
    "print('testX_onehot shape: ', testX_onehot.shape , 'testY shape: ', testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = len(X_pos_onehot)/(len(X_pos_onehot)+len(X_neg_onehot)*1)  # modulate the imbalance of pos/neg = 1:1\n",
    "loss_fun = focal_loss(gamma=[2, 2], alpha=alpha)\n",
    "clf = T3SEClassEstimator(n_outputs=2, fmap_shape1=(200, 20, 1), dense_layers=[256, 32], epochs=8000, monitor='val_auc', metric='ACC',\n",
    "                          gpuid=0, batch_size=128, lr=1e-4, decay=1e-3, loss=loss_fun)  # train at least 20 Epochs\n",
    "clf.patience = 21  # no less than 20\n",
    "clf.fit(trainX_onehot[:,:200,:,:], trainY, (testX_d_onehot[:,:200,:,:], testX_d_onehot[:,:200,:,:]), (testY_d, testY_d))\n",
    "print('Best epochs: %.2f, Best loss: %.2f' % (clf._performance.best_epoch, clf._performance.best))\n",
    "\n",
    "import time\n",
    "curr_time = (time.strftime(\"%m-%d-%H%M\",time.localtime()))\n",
    "clf._model.save('./saved_model/'+curr_time+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_list = [i for i in os.listdir('./saved_model') if 'h5' in i]\n",
    "\n",
    "clf1 = T3SEClassEstimator(n_outputs=2, fmap_shape1=(200, 20, 1), dense_layers=[256, 32],\n",
    "                           gpuid=0, batch_size=128, lr=1e-4, decay=1e-3, loss=loss_fun)\n",
    "loss_fun = focal_loss(gamma=[1, 1], alpha=0.5)\n",
    "for saved_model_name in model_list:\n",
    "    clf1._model = tf.keras.models.load_model('./saved_model/'+saved_model_name, custom_objects={'focal_loss_fixed':loss_fun})\n",
    "    proba1 = clf1._model.predict(testX_d_onehot[:,:200,:,:])\n",
    "    pre_dual = np.round(proba1)    \n",
    "    print(saved_model_name, sum(pre_dual[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test single fasta\n",
    "\n",
    "# test_single_fasta = 'MTTLTTRQIQLAHAWTSVHTGAGLALDWVADVAEKVEEIATKADALSRDLHRARNLSRSLGRVSTTPMGIGFFGLSQAGKSYLISALAADEKGQLLTRLGT'\n",
    "# fastas = [test_single_fasta]\n",
    "with open('test.fasta') as f:\n",
    "    fastas = f.readlines()\n",
    "\n",
    "def Encode(data):\n",
    "    alphabet = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    integer_encoded = []\n",
    "    for char in data:\n",
    "        if char in char_to_int:\n",
    "            integer_encoded.append(char_to_int[char])\n",
    "        else:\n",
    "            integer_encoded.append(-1)\n",
    "    onehot_encoded = list()\n",
    "    for value in integer_encoded:\n",
    "        letter = [0 for _ in range(len(alphabet))]\n",
    "        if value >= 0:\n",
    "             letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "    return onehot_encoded\n",
    "\n",
    "onehot_out = []\n",
    "for f in fastas:\n",
    "    if not '>' in f:\n",
    "        f = f.strip('\\n')\n",
    "        if len(f) > 1000:\n",
    "            f = f[:1000]\n",
    "        else:\n",
    "            for i in range(len(f),1000):\n",
    "                f = f + 'X'\n",
    "        seq = Encode(f)\n",
    "        onehot_out.append(seq)\n",
    "onehot_out = np.array(onehot_out)\n",
    "\n",
    "import os\n",
    "model_list = [i for i in os.listdir('./saved_model') if 'h5' in i]\n",
    "\n",
    "loss_fun = focal_loss(gamma=[2, 2], alpha=0.5)\n",
    "clf1 = T3SEClassEstimator(n_outputs=2, fmap_shape1=(200, 20, 1), dense_layers=[256, 32], epochs=8000, monitor='val_auc', metric='ACC',\n",
    "                           gpuid=0, batch_size=128, lr=1e-4, decay=1e-3, loss=loss_fun)\n",
    "for saved_model_name in model_list:\n",
    "    clf1._model = tf.keras.models.load_model('./saved_model/'+saved_model_name, custom_objects={'focal_loss_fixed':loss_fun})\n",
    "    proba1 = clf1._model.predict(onehot_out[:,:200,:])\n",
    "    pre_dual = np.round(proba1)\n",
    "    print(saved_model_name, sum(pre_dual))\n",
    "    # print(*list((proba1[:,1])))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db76939b3139c0a9e3a806c3de61c5159f96489d720ba04d971e57d5e8c586b8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tf24-GPU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
